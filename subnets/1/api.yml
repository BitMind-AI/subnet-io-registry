baseUrl: "https://api.corcel.io/v1"
name: "Standard Chat (Subnet 1)"
description: "Basic chat completion endpoint using standard language models."
endpoints:
  - path: /chat
    externalPath: /chat/completions
    method: POST
    auth:
      type: header
      key: "Authorization"
      value: "{{api-key}}"
    headers:
      Content-Type: application/json
    requestSchema:
      type: object
      properties:
        model:
          type: string
          default: llama-3
          enum:
            [
              "llama-3",
              "llama-3-1-8b",
              "llama-3-2-3b",
              "llama-3-1-70b",
              "mixtral-8x7b",
              "deepseek-r1-qwen-32b",
              "Qwen/QwQ-32B",
              "qwen-2-5-7b",
            ]
          description: "Model used for the chat"
        messages:
          type: array
          items:
            type: object
            properties:
              role:
                type: string
                enum: [user, assistant, system]
              content:
                type: string
            required: [role, content]
        temperature:
          type: number
          default: 0.1
        max_tokens:
          type: integer
          default: 500
        top_p:
          type: integer
          default: 1
        stream:
          type: boolean
          default: true
        logprobs:
          type: boolean
          default: false
      required: [model, messages]
