baseUrl: "https://api.corcel.io/v1"
name: "Standard Chat (Subnet 1)"
description: "Basic chat completion endpoint using standard language models."
endpoints:
  - path: /chat
    externalPath: /chat/completions
    method: POST
    summary: "Engage in chat with various AI models"
    description: "Facilitates conversational interactions with AI models available on Bittensor Subnet 1. You can ask questions, request text generation, or have a general chat. This tool supports a variety of language models; please refer to the 'model' parameter options for a complete list of choices (default is 'llama-3')."
    auth:
      type: header
      key: "Authorization"
      value: "{{api-key}}"
    headers:
      Content-Type: application/json
    requestSchema:
      type: object
      properties:
        model:
          type: string
          description: "Model used for the chat"
          enum:
            [
              "llama-3",
              "llama-3-1-8b",
              "llama-3-2-3b",
              "llama-3-1-70b",
              "mixtral-8x7b",
              "deepseek-r1-qwen-32b",
              "Qwen/QwQ-32B",
              "qwen-2-5-7b",
            ]
          default: "llama-3"
        messages:
          type: array
          items:
            type: object
            properties:
              role:
                type: string
                description: "Role of the message sender"
                enum: [user, assistant, system]
                default: "user"
              content:
                type: string
            required: [role, content]
        temperature:
          type: number
          default: 0.1
        max_tokens:
          type: integer
          default: 500
        top_p:
          type: integer
          default: 1
        stream:
          type: boolean
          default: true
        logprobs:
          type: boolean
          default: false
      required: [model, messages]
